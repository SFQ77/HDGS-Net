{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e89c687-dd56-47d2-84f5-c63ad79d4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "Because the classification of the positive and negative strands at \n",
    "different positions of SNFR and NNFR is not ideal,they are directly merged into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a973a-571f-4546-9b50-4e01231764c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f85679-f655-4574-901a-e913fde0cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (227, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR+1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR+1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR+1N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR+1N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08e1d2-490e-410e-a2ec-4f2d000edf45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e489e8d-1419-4b21-aa30-41d3ff3086f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (227, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR+2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR+2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR+2N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR+2N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff8901e-daa6-4c7a-b4e3-05450eb08ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7435622d-71ae-495e-8e8e-5f143e4139aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (227, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR+3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR+3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR+3N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR+3N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd3b192-cd76-42d6-bc7e-701791d869cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109efbdd-7609-4fe9-ba5c-9317bc0b3de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (227, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR-1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR-1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR-1N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR-1N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52242027-a481-4bdf-b4fa-e441997dedc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ea87a2-2da9-4d2d-9368-b119326db40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (227, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR-2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR-2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR-2N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR-2N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3713ee-3229-4ad0-9016-df388b181d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce12df76-b4e5-4d84-8af7-e9bf910f622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (227, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR-3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR-3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR-3N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/SNFR-3N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20edbf6-b64a-45e1-b7d5-1a85e6a986c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40b36d68-3e4a-4554-becf-2822a3129463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (118, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR+1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR+1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR+1N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR+1N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b2338e-273a-45cd-bba7-6a7d19547f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de14d658-e2e6-4a10-bc16-94bd38af168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (118, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR+2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR+2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR+2N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR+2N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d9c58-6d15-4cec-9c73-77e276f373ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b46c33-be7d-4e02-9c5e-d259baf76df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (118, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR+3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR+3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR+3N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR+3N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81403a4a-c201-4b18-98a2-aa692eb47204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7133206c-ad6c-4fbf-88ab-67e0e4b52ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (118, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR-1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR-1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR-1N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR-1N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d6e172-006f-4092-bfc0-5e59d623c87b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6adfde61-a5fc-4dc6-8478-48915ee18bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (118, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR-2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR-2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR-2N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR-2N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be5bc8-1dce-4dd4-a65b-e41ad226c2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "134dd08e-0e3d-4dcb-9fda-143816ed7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (118, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR-3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR-3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR-3N.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file = h5py.File('TSS-TTS Matrix/NNFR-3N.h5', 'r')\n",
    "nuar = merged_file['Nuar'][:]\n",
    "print(f\"The shape of the merged data: {nuar.shape}\")\n",
    "merged_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af04909-962f-4a81-aa32-fd06bf529e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7252a77-accc-4e9d-b2c5-f754cc052516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb2f24-2cfe-4d2e-ac8c-f684f5155467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ea9d6-8a17-4894-a5a7-ecdb4de6afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Merge the numerical matrices of SNFR and NNFR at the same positions into a larger matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b55b230-dcf8-4fdc-8792-67893fa8296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (236, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR+1N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR+1N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int) \n",
    "y2 = np.ones(min_samples, dtype=int)   \n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/NNFR_SNFR+1N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71e668-3780-416c-8d8d-bf21eb142ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a4d0398-def0-4871-8671-b2cc3799c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (236, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR+2N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR+2N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int) \n",
    "y2 = np.ones(min_samples, dtype=int)   \n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/NNFR_SNFR+2N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c96335-29b2-489d-9586-2f60abe04457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b7d0bf-acfd-46fd-9144-f32a5e5cacbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (236, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR+3N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR+3N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int) \n",
    "y2 = np.ones(min_samples, dtype=int)   \n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/NNFR_SNFR+3N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f61ed-ffe6-4e9f-bc22-eb7621720db5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ea69d9f-b8ba-401e-a967-9484289c6ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (236, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR-1N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR-1N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int) \n",
    "y2 = np.ones(min_samples, dtype=int)   \n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/NNFR_SNFR-1N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15d69d-fe50-4107-8ca1-c32b28eafb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "256a9b9f-885a-4f9e-b2fb-0f062faf4b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (236, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR-2N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR-2N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int) \n",
    "y2 = np.ones(min_samples, dtype=int)   \n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/NNFR_SNFR-2N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f2ab84-00ee-4a9e-9c73-84d70ab07437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87c360f5-a0fa-4e0a-b7bf-9100ef002aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (236, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR-3N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR-3N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int) \n",
    "y2 = np.ones(min_samples, dtype=int)   \n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/NNFR_SNFR-3N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ed937-71b0-4ad0-82c6-45efc8471412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a461f-49dc-48c4-bf8b-41e266bc7c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2ece99-35ca-4527-a137-75566f8bba68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0651cdcf-bd6b-4d48-91ae-0337e966c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The improved convolutional neural network model HDGS-Net is used to \n",
    "train classification models for each merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00424e96-2a0d-4b7a-b8b4-f87fccc653f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR+1N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 2-1.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s]) \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])   \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=35,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bb379-1131-4b6b-ae76-c94ad339b25c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15789093-082c-46d7-8bb2-c303b36cdfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR+2N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 2-2.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s]) \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])   \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=35,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1673ad-304b-4c97-8896-643932adf096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca0f8b9c-aae7-435e-8c6c-0448ce8a92a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR+3N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 2-3.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s]) \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])   \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=35,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45c898-3c63-482c-ac30-d9a3f7cf4e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec13540-f195-480b-afc4-4012ab3de327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR-1N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 2-4.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s]) \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])   \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=35,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544b3e9c-5f7c-4d01-9fbf-d0ac8f87c0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7ffc52-9ce8-4c4b-9968-76f18895f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR-2N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 2-5.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s]) \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])   \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=35,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80fc5f2-8577-412c-a722-73e29e38d000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4e6867-c68d-40dd-9fe5-7ef43805c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR-3N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 2-6.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s]) \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])   \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=35,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206888a0-927f-49a1-9b07-2cf2917b4ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbcd8b-c867-4683-b4e4-c5090f4f1998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d010cf9-f24b-408a-bb58-fb3f33f30276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635443a-acc6-4954-b74a-75c2c2b51af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use a trained deep learning model to classify the merged data of SNFR and NNFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebdca17-a70a-444d-a04f-db80423e1fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 923ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.67      0.22      0.33        27\n",
      "      class1       0.46      0.86      0.60        21\n",
      "\n",
      "    accuracy                           0.50        48\n",
      "   macro avg       0.56      0.54      0.47        48\n",
      "weighted avg       0.58      0.50      0.45        48\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 272ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 252ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 261ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.5465\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR+1N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 2-1.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0422cd24-e22c-4b78-a5c4-d9c153518cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8757c828-bf83-431d-a57c-957e84fc3616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step   \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.33      0.04      0.07        27\n",
      "      class1       0.42      0.90      0.58        21\n",
      "\n",
      "    accuracy                           0.42        48\n",
      "   macro avg       0.38      0.47      0.32        48\n",
      "weighted avg       0.37      0.42      0.29        48\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 260ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 265ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.5337\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR+2N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 2-2.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76dc987-5101-4b78-bcb2-79e56071488e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4d53f6-2b60-4413-9cc6-98ecb0459a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 929ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.50      0.07      0.13        27\n",
      "      class1       0.43      0.90      0.58        21\n",
      "\n",
      "    accuracy                           0.44        48\n",
      "   macro avg       0.47      0.49      0.36        48\n",
      "weighted avg       0.47      0.44      0.33        48\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 292ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 279ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 281ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.5337\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR+3N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 2-3.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607a5d2-dfa0-4b2a-b45c-70afbe82127a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fa7a44-204d-43bb-8558-1a4d1055ed09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 907ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.57      0.15      0.24        27\n",
      "      class1       0.44      0.86      0.58        21\n",
      "\n",
      "    accuracy                           0.46        48\n",
      "   macro avg       0.51      0.50      0.41        48\n",
      "weighted avg       0.51      0.46      0.39        48\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 274ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 270ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 280ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 276ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.5378\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR-1N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 2-4.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635678a2-ee04-4882-b3a7-79974f0dd620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bfdfdd0-65ee-4576-9a80-1da8141575a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 954ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.00      0.00      0.00        27\n",
      "      class1       0.40      0.86      0.55        21\n",
      "\n",
      "    accuracy                           0.38        48\n",
      "   macro avg       0.20      0.43      0.27        48\n",
      "weighted avg       0.18      0.38      0.24        48\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 271ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 283ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.4785\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR-2N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 2-5.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d738297-3204-4347-b34e-3c3a66ebfc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0eb4085-55f1-4285-96e9-53837f303854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 893ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.40      0.07      0.12        27\n",
      "      class1       0.42      0.86      0.56        21\n",
      "\n",
      "    accuracy                           0.42        48\n",
      "   macro avg       0.41      0.47      0.34        48\n",
      "weighted avg       0.41      0.42      0.32        48\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 349ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 405ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.5126\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/NNFR_SNFR-3N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(236, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 2-6.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5fd459-79af-4b10-b6df-717467ad1c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
