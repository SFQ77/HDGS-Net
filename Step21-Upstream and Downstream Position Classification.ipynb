{
 "cells": [
  {
   "cell_type": "raw",
   "id": "79b482a5-4940-4263-acb4-aed28a2bf500",
   "metadata": {},
   "source": [
    "Because the classification of the same positions of SNFR and NNFR is not ideal, they are directly merged into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08904129-9ddb-4a7f-96a1-c93e9a085fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "203b07ae-e80e-429a-8405-3218cf34cb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (345, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR+1N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR+1N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/+1N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b394ff72-b015-4203-bcd4-d8c3ff342671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9978c3-af23-45fe-ad84-fc84e7953b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (345, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR+2N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR+2N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/+2N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79442d97-d734-4551-96b6-eb513303d762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab639d71-c67c-4c49-a6d8-8b1ac469d5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (345, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR+3N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR+3N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/+3N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337b7a6-6386-4e77-87b3-b7c7c48ceaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fb39af0-a849-4963-9d11-88b1bd1b9a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (345, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR-1N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR-1N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/-1N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fa5b2-37e8-49b7-9bcb-61c31bc99a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a593521-6981-420c-8a5f-4e90a62b166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (345, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR-2N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR-2N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/-2N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09102811-5719-42c2-a243-c5c93aaeafe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8902880-8104-4741-8b75-24b605a00962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (345, 16, 146)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/SNFR-3N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/NNFR-3N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/-3N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8341249-7568-474a-b9ba-473d9f456ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae31c23-f3c3-46f5-bbad-7c56d75b7085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac24847-7ef9-42f1-9841-5ff90087c7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "55e8cdcb-42e1-41db-a79a-979c558aabaf",
   "metadata": {},
   "source": [
    "Then, merge the numerical matrices of the positive and negative strands at the same positions into a larger matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4be649fb-63ff-4ca5-b446-7eb320297159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (690, 16, 146)\n",
      "The shape of the merged labels: (690,)\n",
      "The distribution of the labels: 0 - 345, 1 - 345\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/+1N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/-1N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int)\n",
    "y2 = np.ones(min_samples, dtype=int)\n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/-+_1N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")\n",
    "    print(f\"The shape of the merged labels: {label_merged.shape}\")\n",
    "    print(f\"The distribution of the labels: 0 - {np.sum(label_merged == 0)}, 1 - {np.sum(label_merged == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d6251-1e19-468b-8a59-344ce2a2f5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d12902-981b-4a83-aecb-efe908d03f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (690, 16, 146)\n",
      "The shape of the merged labels: (690,)\n",
      "The distribution of the labels: 0 - 345, 1 - 345\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/+2N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/-2N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int)\n",
    "y2 = np.ones(min_samples, dtype=int)\n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/-+_2N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")\n",
    "    print(f\"The shape of the merged labels: {label_merged.shape}\")\n",
    "    print(f\"The distribution of the labels: 0 - {np.sum(label_merged == 0)}, 1 - {np.sum(label_merged == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b79bd2-20aa-405b-8229-ac3ad72f7d34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77534530-dbd1-4ec0-95a6-611f28d9cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the merged data: (690, 16, 146)\n",
      "The shape of the merged labels: (690,)\n",
      "The distribution of the labels: 0 - 345, 1 - 345\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "file1 = h5py.File('TSS-TTS Matrix/+3N.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/-3N.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y1 = np.zeros(min_samples, dtype=int)\n",
    "y2 = np.ones(min_samples, dtype=int)\n",
    "y = np.concatenate((y1, y2), axis=0)\n",
    "merged_file_path = 'TSS-TTS Matrix/-+_3N.h5'\n",
    "with h5py.File(merged_file_path, 'w') as merged_file:\n",
    "    merged_file.create_dataset('Nuar', data=X)\n",
    "    merged_file.create_dataset('label', data=y)\n",
    "file1.close()\n",
    "file2.close()\n",
    "with h5py.File(merged_file_path, 'r') as merged_file:\n",
    "    nuar_merged = merged_file['Nuar'][:]\n",
    "    label_merged = merged_file['label'][:]\n",
    "    print(f\"The shape of the merged data: {nuar_merged.shape}\")\n",
    "    print(f\"The shape of the merged labels: {label_merged.shape}\")\n",
    "    print(f\"The distribution of the labels: 0 - {np.sum(label_merged == 0)}, 1 - {np.sum(label_merged == 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f1e2b-aeb8-459e-a6f3-03ed9b75098a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dd242-fce1-4449-b68f-e2565a31cb13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e3ff6-e75e-4319-8cba-3c2fa29480ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8f6721-d7d0-49a9-a51e-fe67ad50fed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "eceb5559-d7e5-4d44-bcce-6b1e87ea4391",
   "metadata": {},
   "source": [
    "Then use these merged numerical matrices to train the improved convolutional neural network classification model HDGS-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "791037d0-2e62-4559-94c0-8eda28feae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/-+_1N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(690,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 3-2.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=30,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5dc7c0-fe5b-4bc0-86ad-287b685c41ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01177b53-c1db-4d28-be6d-8886bfc82ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/-+_2N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(690,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 3-1.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=30,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f9451-a1b8-45e9-b211-9e775e5ae963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4d0d8e-09e1-4cb5-9499-17611934a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/-+_3N.h5','r') \n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(690,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 3-3.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])\n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) \n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])\n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])\n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              metrics=['accuracy', Precision(name='precision'), Recall(name='recall')])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=30,batch_size=64,verbose=0,callbacks = callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf5627-bae3-4352-90d6-7dcdffe8121a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f552f3-6eb1-4847-9e92-4d1cad1a3a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec574fa4-7066-4dae-a09f-71c171303ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f986cb83-839c-4f1d-b4d1-fc481edcd350",
   "metadata": {},
   "source": [
    "Use the trained deep learning model to classify the positive and negative strands at the same positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b7cc4e6-adf3-4195-b636-ccc7698ba0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.55      0.25      0.34        72\n",
      "      class1       0.49      0.77      0.60        66\n",
      "\n",
      "    accuracy                           0.50       138\n",
      "   macro avg       0.52      0.51      0.47       138\n",
      "weighted avg       0.52      0.50      0.46       138\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step\n",
      "The average accuracy rate of five-fold cross-validation：0.4725\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/-+_1N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(690, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 3-1.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7acae2-d8c5-4545-93c2-ea6b3cc81c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f8cfec-623b-4652-b5d9-995fcf9cd2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.31      0.06      0.09        72\n",
      "      class1       0.46      0.86      0.60        66\n",
      "\n",
      "    accuracy                           0.44       138\n",
      "   macro avg       0.38      0.46      0.35       138\n",
      "weighted avg       0.38      0.44      0.33       138\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step\n",
      "The average accuracy rate of five-fold cross-validation：0.4783\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/-+_2N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(690, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 3-2.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecbbe52-039e-4927-ae1d-75e838e50018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef982a0-a900-494d-9cb2-0319c4878ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 597ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.50      0.10      0.16        72\n",
      "      class1       0.48      0.89      0.62        66\n",
      "\n",
      "    accuracy                           0.48       138\n",
      "   macro avg       0.49      0.50      0.39       138\n",
      "weighted avg       0.49      0.48      0.38       138\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 420ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 426ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 433ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 475ms/step\n",
      "The average accuracy rate of five-fold cross-validation：0.5087\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/-+_3N.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(690, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 3-3.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation：{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e289e5d9-54fc-48f5-bef7-a333ddbd5092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
