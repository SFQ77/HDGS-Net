{
 "cells": [
  {
   "cell_type": "raw",
   "id": "809ef72b-e395-4465-a35f-15bae07e0b88",
   "metadata": {},
   "source": [
    "Merge the numerical matrices and label data of the positive and negative strands at different positions of SNFR into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ff8e65-b775-4e2c-b2d8-5a3bf70da391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (224, 16, 146)\n",
      "Label Shape of the dataset: (224,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(112), np.int64(1): np.int64(112)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR+1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR+1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_SNFR+1N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_SNFR+1N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a0e06-1029-42ac-a396-241fdbc139c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad27b293-0071-46db-9156-1b02dfed98c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (224, 16, 146)\n",
      "Label Shape of the dataset: (224,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(112), np.int64(1): np.int64(112)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR+2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR+2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_SNFR+2N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_SNFR+2N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e1d1d-2055-49a4-8bb7-cfa610610260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3bb96cf-0ec9-40eb-aea0-6360ddde02c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (224, 16, 146)\n",
      "Label Shape of the dataset: (224,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(112), np.int64(1): np.int64(112)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR+3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR+3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_SNFR+3N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_SNFR+3N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1feb593-5f09-4dc1-ba0c-e9e0e78d7f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "971dc40c-5197-4f30-9d87-b1f6f0d0afd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (224, 16, 146)\n",
      "Label Shape of the dataset: (224,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(112), np.int64(1): np.int64(112)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR-1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR-1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_SNFR-1N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_SNFR-1N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72978fd6-b9dd-46d1-ba95-248aa65293b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4363a61-ae9b-46b0-ba18-be0acd933d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (224, 16, 146)\n",
      "Label Shape of the dataset: (224,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(112), np.int64(1): np.int64(112)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR-2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR-2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_SNFR-2N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_SNFR-2N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f6187f-b704-48ce-9f67-ac0e9389098b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ccf2a6a-9a26-440f-91cb-d338f862f6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (224, 16, 146)\n",
      "Label Shape of the dataset: (224,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(112), np.int64(1): np.int64(112)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+SNFR-3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-SNFR-3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_SNFR-3N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_SNFR-3N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ef2142-dc36-4966-aa55-cf53b4088684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "53952f51-b62f-49ed-8fc8-0a6c2c4318ef",
   "metadata": {},
   "source": [
    "Merge the numerical matrices and label data of the positive and negative strands at different positions of NNFR into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3354d8e6-38b0-43cc-ac16-804ef2c2684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (112, 16, 146)\n",
      "Label Shape of the dataset: (112,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(56), np.int64(1): np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR+1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR+1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_NNFR+1N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_NNFR+1N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c912f57-557f-419c-a627-03a928cb53bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e63275e-1557-4a4f-bf26-5575bd78ad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (112, 16, 146)\n",
      "Label Shape of the dataset: (112,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(56), np.int64(1): np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR+2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR+2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_NNFR+2N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_NNFR+2N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73357e50-17f8-4841-9668-76bdc30fb569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bfb8df4-0f2a-443d-b4d3-e8a750536db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (112, 16, 146)\n",
      "Label Shape of the dataset: (112,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(56), np.int64(1): np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR+3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR+3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_NNFR+3N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_NNFR+3N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e67a1e-6732-47bc-8a75-2c411a5db9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ebe3940-73d3-4793-ac10-ebc97f3e1e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (112, 16, 146)\n",
      "Label Shape of the dataset: (112,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(56), np.int64(1): np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR-1N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR-1N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_NNFR-1N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_NNFR-1N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95fb89a-d408-4124-b208-9ff4a6f779c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6c31553-90b6-4e1d-b970-866c173b66b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (112, 16, 146)\n",
      "Label Shape of the dataset: (112,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(56), np.int64(1): np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR-2N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR-2N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_NNFR-2N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_NNFR-2N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1b7f7-0e28-45b2-b0f1-9fa74af7b1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14ccc984-1d51-45f3-91e5-aeb2020082d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuar Shape of the dataset: (112, 16, 146)\n",
      "Label Shape of the dataset: (112,)\n",
      "Unique values of the labels and their counts: {np.int64(0): np.int64(56), np.int64(1): np.int64(56)}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "file1 = h5py.File('TSS-TTS Matrix/matrix_+NNFR-3N-ALL.h5', 'r')\n",
    "file2 = h5py.File('TSS-TTS Matrix/matrix_-NNFR-3N-ALL.h5', 'r')\n",
    "nuar1 = file1['Nuar'][:]\n",
    "nuar2 = file2['Nuar'][:]\n",
    "labels1 = np.zeros(nuar1.shape[0], dtype=int)\n",
    "labels2 = np.ones(nuar2.shape[0], dtype=int)\n",
    "min_samples = min(nuar1.shape[0], nuar2.shape[0])\n",
    "nuar1 = nuar1[:min_samples]\n",
    "labels1 = labels1[:min_samples]\n",
    "nuar2 = nuar2[:min_samples]\n",
    "labels2 = labels2[:min_samples]\n",
    "X = np.concatenate((nuar1, nuar2), axis=0)\n",
    "y = np.concatenate((labels1, labels2), axis=0)\n",
    "merged_file = h5py.File('TSS-TTS Matrix/matrix_NNFR-3N-ALL.h5', 'w')\n",
    "merged_file.create_dataset('Nuar', data=X)\n",
    "merged_file.create_dataset('label', data=y)\n",
    "merged_file.close()\n",
    "file1.close()\n",
    "file2.close()\n",
    "merged_file_path = 'TSS-TTS Matrix/matrix_NNFR-3N-ALL.h5'\n",
    "with h5py.File(merged_file_path, 'r') as f:\n",
    "    nuar = f['Nuar']\n",
    "    label = f['label']\n",
    "    print(f\"Nuar Shape of the dataset: {nuar.shape}\")\n",
    "    print(f\"Label Shape of the dataset: {label.shape}\")\n",
    "    unique_labels, counts = np.unique(label, return_counts=True)\n",
    "    print(f\"Unique values of the labels and their counts: {dict(zip(unique_labels, counts))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec417e9-2597-4a09-a582-f2754cdc0a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d87e64-f3a8-4ad3-9d5e-a75bd56b64a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1bf2a9-f859-404a-ab3b-2b493bd36471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "ed78b1c1-9602-4b4c-a0e9-3f64587319a1",
   "metadata": {},
   "source": [
    "The improved convolutional neural network model HDGS-Net is used to train classification models for each merged dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a14f94-db98-499e-8f1c-c2ecc5544141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR+1N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-1.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fcd32a-27ea-41f4-96d2-4145f2ad7de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9389ddf7-e987-428b-b383-72d23c734452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR+2N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-2.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c9ce06-71f2-4565-bfd0-4294bd3cc87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3554d23a-c00b-4c77-a6ab-cd9be6ce1b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR+3N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-3.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcc8599-f064-4274-86e4-b40511a1d6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "047d6245-073a-4413-9b39-086df58e6fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR-1N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-4.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b6d98-d21b-4b3e-acb5-6a141a7afc0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d80c71c-36fa-462d-809b-93cd4f179c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR-2N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-5.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c43d2-5f99-4a12-88d1-f32445b8e753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26873342-c7a0-48ff-8f97-a0423b4912ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR-3N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-6.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ce989f-db21-4e4d-8140-3ea5663a04a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f299884-a541-418b-8406-d3f48c04cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR+1N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-7.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4785a2-3948-46c3-b221-d008b9f39cda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e23eee39-3f93-4f70-860e-01763e5fb2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR+2N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-8.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff315b-cfbe-4385-b3a5-05342f6d9956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc9b360a-9ffc-4b99-aa31-b28de8b1e1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR+3N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-9.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1ea25-e66a-439b-bd01-276b297c93c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb4db823-dc21-4b1b-850e-a845d7778b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR-1N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-10.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdca09e-9a24-41ba-9d97-7d65c1a13d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84303d4e-84f1-4022-8472-4791b0bf1e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR-2N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-11.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab3f6da-b4db-4907-8ffc-7bcf49c3a0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79166c91-8a77-486e-8eb6-19d45ec728a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, BatchNormalization, \n",
    "Flatten,Dense, Lambda, Multiply, AveragePooling2D, Activation)\n",
    "from tensorflow.keras.optimizers import Optimizer \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from sklearn.model_selection import cross_val_score \n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR-3N-ALL.h5','r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112,16,146,1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "import os\n",
    "save_dir = 'TSS-TTS Model'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "callbacks_list = [\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=15),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=os.path.join(save_dir, 'Classification Model 1-12.keras'), monitor='val_loss', save_best_only=True)]\n",
    "def Conv2d_BN(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def Conv2d_NB(x, nb_filter,kernel_size, padding='valid',strides=(1,1),data_format='channels_last',\n",
    "              dilation_rate=(1,1),activation='relu',name=None):\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,data_format='channels_last',\n",
    "               activation='relu',dilation_rate=dilation_rate,name=conv_name)(x)\n",
    "    x = BatchNormalization(name=bn_name)(x)\n",
    "    return x\n",
    "def InceptionA(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])    \n",
    "    branch_1x11_t = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x11_s = Activation('sigmoid')(branch_1x11_s)\n",
    "    branch_1x11_c = keras.layers.Multiply()([branch_1x11_t,branch_1x11_s])    \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])    \n",
    "    branch_1x11_dt = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Conv2d_BN(x,nb_filter,(1,11), padding='same',strides=(1,1),\n",
    "                               data_format='channels_last',activation='relu',\n",
    "                               dilation_rate=(1,5),name=None)\n",
    "    branch_1x11_ds = Activation('sigmoid')(branch_1x11_ds)\n",
    "    branch_1x11_dc = keras.layers.Multiply()([branch_1x11_dt,branch_1x11_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,\n",
    "                                          branch_1x7_dc,branch_1x11_dc]) \n",
    "    return x\n",
    "def InceptionB(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])   \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])       \n",
    "    branch_1x7_t = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                             data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x7_s = Activation('sigmoid')(branch_1x7_s)\n",
    "    branch_1x7_c = keras.layers.Multiply()([branch_1x7_t,branch_1x7_s])  \n",
    "    branch_1x7_dt = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Conv2d_BN(x,nb_filter,(1,7), padding='same',strides=(1,1),\n",
    "                              data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,3),name=None)\n",
    "    branch_1x7_ds = Activation('sigmoid')(branch_1x7_ds)\n",
    "    branch_1x7_dc = keras.layers.Multiply()([branch_1x7_dt,branch_1x7_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x7_c,branch_1x7_dc]) #\n",
    "    return x\n",
    "def InceptionC(x,nb_filter):\n",
    "    branch_1x1_t = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Conv2d_BN(x,nb_filter,(1,1), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x1_s = Activation('sigmoid')(branch_1x1_s)\n",
    "    branch_1x1_c = keras.layers.Multiply()([branch_1x1_t,branch_1x1_s])    \n",
    "    branch_1x3_t = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',name=None)\n",
    "    branch_1x3_s = Activation('sigmoid')(branch_1x3_s)\n",
    "    branch_1x3_c = keras.layers.Multiply()([branch_1x3_t,branch_1x3_s])  \n",
    "    branch_1x3_dt = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Conv2d_BN(x,nb_filter,(1,3), padding='same',strides=(1,1),data_format='channels_last',activation='relu',\n",
    "                              dilation_rate=(1,2),name=None)\n",
    "    branch_1x3_ds = Activation('sigmoid')(branch_1x3_ds)\n",
    "    branch_1x3_dc = keras.layers.Multiply()([branch_1x3_dt,branch_1x3_ds])\n",
    "    x = keras.layers.Concatenate(axis=3)([branch_1x1_c,branch_1x3_c,branch_1x3_dc]) \n",
    "    return x\n",
    "def TestNet(input_shape=None):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = BatchNormalization()(inpt)\n",
    "    x = InceptionA(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionA(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionB(x,128)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = InceptionC(x,64)\n",
    "    x = MaxPooling2D(pool_size=(1,3),strides=(1,3),padding='valid',data_format='channels_last')(x)\n",
    "    x = Flatten(data_format='channels_last')(x)\n",
    "    x = Dense(256,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(32,activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Dense(1,activation='sigmoid')(x)\n",
    "    model = Model(inpt,x,name='inception')\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.Adam(learning_rate=1e-4),metrics=['accuracy'])\n",
    "    return model\n",
    "model = TestNet(input_shape=(16,146,1))\n",
    "model.load_weights('Convolutional Neural Network Model/Regression weights (no10).h5')\n",
    "model.fit(X_train,y_train,validation_split=0.20,epochs=60,batch_size=64,verbose=0,callbacks=callbacks_list)\n",
    "print(\"Training completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb50914-155e-4dba-b6c4-12c22488e090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b066e1e-ca78-4ac5-84c9-e2c508c32574",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23020e1a-1834-44f8-811d-21305f9ea94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e6b5bfb1-568b-4a64-8adb-356972f44654",
   "metadata": {},
   "source": [
    "Use a trained deep learning model to classify the merged positive and negative strand data of SNFR or NNFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd21c395-916f-4b90-bfd7-af5e4d64337a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 905ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.60      0.31      0.41        29\n",
      "      class1       0.33      0.62      0.43        16\n",
      "\n",
      "    accuracy                           0.42        45\n",
      "   macro avg       0.47      0.47      0.42        45\n",
      "weighted avg       0.51      0.42      0.42        45\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 228ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 221ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.6072\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR+1N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-1.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d5061-2eba-40a2-b2ef-b129a926f5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a135a3-08a1-4e24-bf8d-40b15a7d41d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 850ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.00      0.00      0.00        29\n",
      "      class1       0.31      0.81      0.45        16\n",
      "\n",
      "    accuracy                           0.29        45\n",
      "   macro avg       0.15      0.41      0.22        45\n",
      "weighted avg       0.11      0.29      0.16        45\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 211ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 224ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 207ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5133\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR+2N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-2.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e6188-7475-4672-abb0-b34aa59526e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "086074ea-5e6f-4111-805e-c4de2bcd2349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 852ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.67      0.28      0.39        29\n",
      "      class1       0.36      0.75      0.49        16\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.52      0.51      0.44        45\n",
      "weighted avg       0.56      0.44      0.43        45\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 215ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 217ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 207ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5580\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR+3N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-3.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fcd83-064c-4686-a1e5-636a1a293cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8f78882-a206-48d2-bf9d-de8fc00034c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 821ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       1.00      0.14      0.24        29\n",
      "      class1       0.39      1.00      0.56        16\n",
      "\n",
      "    accuracy                           0.44        45\n",
      "   macro avg       0.70      0.57      0.40        45\n",
      "weighted avg       0.78      0.44      0.36        45\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 229ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 238ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 222ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5712\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR-1N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-4.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38cc2ce-7910-47c3-8238-8915f2eea4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6696a100-6c32-48f1-804e-fff0c76aaf24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.67      0.14      0.23        29\n",
      "      class1       0.36      0.88      0.51        16\n",
      "\n",
      "    accuracy                           0.40        45\n",
      "   macro avg       0.51      0.51      0.37        45\n",
      "weighted avg       0.56      0.40      0.33        45\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 240ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 233ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 219ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5401\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR-2N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-5.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e176813-ffb1-4d9c-a5c4-be207bc437cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f395a5-9f21-4c95-bcbd-0d40f01db663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 861ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.33      0.03      0.06        29\n",
      "      class1       0.33      0.88      0.48        16\n",
      "\n",
      "    accuracy                           0.33        45\n",
      "   macro avg       0.33      0.45      0.27        45\n",
      "weighted avg       0.33      0.33      0.21        45\n",
      "\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 234ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 236ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 235ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 237ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 230ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5446\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_SNFR-3N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(224, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-6.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d0bcd5-b06a-42cd-b1b0-da39cce42b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b624a6c8-d705-4639-a5d7-09cb25b520ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.67      0.29      0.40         7\n",
      "      class1       0.75      0.94      0.83        16\n",
      "\n",
      "    accuracy                           0.74        23\n",
      "   macro avg       0.71      0.61      0.62        23\n",
      "weighted avg       0.72      0.74      0.70        23\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.6004\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR+1N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-7.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da033bfa-b882-4ea9-a3c6-098c8b3cbd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38432e82-5686-419f-a71f-5daa3b0c513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.00      0.00      0.00         7\n",
      "      class1       0.70      1.00      0.82        16\n",
      "\n",
      "    accuracy                           0.70        23\n",
      "   macro avg       0.35      0.50      0.41        23\n",
      "weighted avg       0.48      0.70      0.57        23\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5008\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix//matrix_NNFR+2N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-8.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bacd17-db0b-477b-ae46-9554aa46db23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a824f0-0c1f-4911-a977-21f97d3bab98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 986ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.00      0.00      0.00         7\n",
      "      class1       0.65      0.81      0.72        16\n",
      "\n",
      "    accuracy                           0.57        23\n",
      "   macro avg       0.33      0.41      0.36        23\n",
      "weighted avg       0.45      0.57      0.50        23\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5012\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR+3N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-9.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names, zero_division=0))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc930e-a2e6-4d1a-908d-45eb20b17b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63212873-f255-451d-84f1-08eee122a44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.22      0.29      0.25         7\n",
      "      class1       0.64      0.56      0.60        16\n",
      "\n",
      "    accuracy                           0.48        23\n",
      "   macro avg       0.43      0.42      0.42        23\n",
      "weighted avg       0.51      0.48      0.49        23\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 981ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5443\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR-1N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-10.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abd82d-79ad-4e2c-a620-add39c1b0522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c244764-b22d-44f0-ae36-761c52cf917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.40      0.29      0.33         7\n",
      "      class1       0.72      0.81      0.76        16\n",
      "\n",
      "    accuracy                           0.65        23\n",
      "   macro avg       0.56      0.55      0.55        23\n",
      "weighted avg       0.62      0.65      0.63        23\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5545\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR-2N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-11.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dabaef-497a-42c5-a827-53570c3ad083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e139fb54-06f0-4def-af6f-754f93092632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 994ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      class0       0.00      0.00      0.00         7\n",
      "      class1       0.65      0.81      0.72        16\n",
      "\n",
      "    accuracy                           0.57        23\n",
      "   macro avg       0.33      0.41      0.36        23\n",
      "weighted avg       0.45      0.57      0.50        23\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step   \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step\n",
      "The average accuracy rate of five-fold cross-validation0.5004\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "f = h5py.File('TSS-TTS Matrix/matrix_NNFR-3N-ALL.h5', 'r')\n",
    "Nuar = f['Nuar']  \n",
    "Nuar = np.array(Nuar)\n",
    "label = f['label']   \n",
    "label = np.array(label)\n",
    "Nuar = Nuar.reshape(112, 16, 146, 1)\n",
    "X_train,X_test,y_train,y_test=train_test_split(Nuar,label,test_size=0.2,random_state=1)\n",
    "model = load_model('TSS-TTS Model/Classification Model 1-12.keras')\n",
    "y_pred= model.predict(X_test) \n",
    "y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "target_names =['class0','class1']\n",
    "print(classification_report(y_test,y_pred,target_names=target_names))\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "for train_index, val_index in kf.split(Nuar):\n",
    "    X_val, y_val = Nuar[val_index], label[val_index]\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred = (y_pred > 0.5).astype(\"int32\")\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f\"The average accuracy rate of five-fold cross-validation{average_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c298ff-606f-4823-be53-e984fde10b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
